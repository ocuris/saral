{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò ‡§™‡§æ‡§Ø‡§•‡§® ‡§∏‡•Ä‡§ñ‡•á‡§Ç ‚Äì ‡§Ü‡§∏‡§æ‡§® ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç\n",
    "## ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø 33: Python ‡§î‡§∞ Web Scraping ‚Äì BeautifulSoup ‡§î‡§∞ Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‡§ï‡§π‡§æ‡§®‡•Ä\n",
    "‡§∞‡§æ‡§Æ ‡§ï‡•ã daily news headlines collect ‡§ï‡§∞‡§®‡•Ä ‡§•‡•Ä‡•§\n",
    "‡§∂‡•ç‡§Ø‡§æ‡§Æ ‡§®‡•á ‡§ï‡§π‡§æ:\n",
    "> \"Python ‡§î‡§∞ BeautifulSoup ‡§ï‡§æ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•ã‡•§ Web scraping ‡§∏‡•á ‡§Ø‡•á ‡§Ü‡§∏‡§æ‡§®‡•Ä ‡§∏‡•á ‡§π‡•ã ‡§ú‡§æ‡§è‡§ó‡§æ‡•§\"\n",
    "\n",
    "‡§∞‡§æ‡§Æ:\n",
    "> \"‡§Ö‡§∞‡•á ‡§µ‡§æ‡§π! ‡§Ö‡§¨ ‡§Æ‡•à‡§Ç ‡§ñ‡•Å‡§¶ headlines scrape ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å ‡§î‡§∞ app ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§ñ‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å‡•§\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
    "- Websites ‡§∏‡•á data automatically collect ‡§ï‡§∞‡§®‡§æ\n",
    "- Mostly HTML parsing\n",
    "- Python ‡§Æ‡•á‡§Ç popular library: `BeautifulSoup` ‡§î‡§∞ `requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries\n",
    "```bash\n",
    "pip install requests beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Simple HTML Request\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.example.com'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "print(soup.prettify())  # formatted HTML\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Extract Specific Tags\n",
    "```python\n",
    "# ‡§∏‡§≠‡•Ä headlines ‡§ï‡•ã extract ‡§ï‡§∞‡§®‡§æ\n",
    "headlines = soup.find_all('h2')  # assume h2 tags contain headlines\n",
    "for h in headlines:\n",
    "    print(h.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Extract Links\n",
    "```python\n",
    "links = soup.find_all('a')  # all anchor tags\n",
    "for link in links:\n",
    "    print(link.get('href'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: CSS Selectors\n",
    "```python\n",
    "items = soup.select('.news-item')  # select elements with class 'news-item'\n",
    "for item in items:\n",
    "    print(item.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "- Respect website `robots.txt`\n",
    "- Avoid too many requests in short time ‚Üí use time.sleep()\n",
    "- Don‚Äôt scrape copyrighted content without permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‡§Ö‡§≠‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®\n",
    "1. ‡§ï‡§ø‡§∏‡•Ä news website ‡§∏‡•á top 5 headlines scrape ‡§ï‡•Ä‡§ú‡§ø‡§è‡•§\n",
    "2. ‡§ï‡§ø‡§∏‡•Ä website ‡§∏‡•á ‡§∏‡§≠‡•Ä links collect ‡§ï‡§∞‡§ï‡•á print ‡§ï‡•Ä‡§ú‡§ø‡§è‡•§\n",
    "3. ‡§ï‡§ø‡§∏‡•Ä online book store page ‡§∏‡•á book titles scrape ‡§ï‡•Ä‡§ú‡§ø‡§è‡•§\n",
    "4. BeautifulSoup ‡§Æ‡•á‡§Ç find() ‡§î‡§∞ find_all() ‡§ï‡§æ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡§ï‡•á ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó tags extract ‡§ï‡•Ä‡§ú‡§ø‡§è‡•§\n",
    "5. Scraped data ‡§ï‡•ã CSV file ‡§Æ‡•á‡§Ç save ‡§ï‡•Ä‡§ú‡§ø‡§è‡•§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§¨‡§æ‡§§‡•á‡§Ç\n",
    "- Web scraping ‚Üí automatic data collection\n",
    "- `requests.get()` ‚Üí page request\n",
    "- `BeautifulSoup` ‚Üí HTML parsing\n",
    "- `find()`, `find_all()`, `select()` ‚Üí elements extract\n",
    "- Scraped data ‚Üí files / databases / APIs ‡§Æ‡•á‡§Ç store ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "üîî **‡§Ö‡§ó‡§≤‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø:** \"Python ‡§î‡§∞ Automation ‚Äì Selenium ‡§î‡§∞ Task Automation\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
